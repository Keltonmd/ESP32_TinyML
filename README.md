# üåü **ESP32_TinyML ‚Äì Infer√™ncia de Redes Neurais no ESP32-S3**

<p align="left">
  <img src="https://img.shields.io/badge/ESP32_S3-Espressif-E7352C?style=for-the-badge&logo=espressif&logoColor=white" />
  <img src="https://img.shields.io/badge/C-00599C?style=for-the-badge&logo=c&logoColor=white" />
  <img src="https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=cplusplus&logoColor=white" />
  <img src="https://img.shields.io/badge/TFLite_Micro-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" />
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" />
  <img src="https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/ESP--IDF-000000?style=for-the-badge&logo=espressif&logoColor=white" />
 
</p>

**Uma solu√ß√£o completa de Edge AI (TinyML) com TensorFlow Lite Micro**

**Autor:** *Kelton Martins Dias*<br>
**Orientador:** *Prof. Felipe Mota*

---

## üìå **Sum√°rio**

1. [Introdu√ß√£o](#-1-introdu√ß√£o)
2. [Objetivo do projeto](#-2-objetivo-do-projeto)
3. [Arquitetura geral](#-3-arquitetura-geral)
4. [Estrutura do reposit√≥rio](#-4-estrutura-do-reposit√≥rio)
5. [Requisitos](#-5-requisitos)

   * [Hardware](#-hardware)
   * [Software](#-software)
6. [Prepara√ß√£o do ambiente (VS Code + ESP-IDF)](#-6-prepara√ß√£o-do-ambiente-vs-code--esp-idf)
7. [Instalando o TensorFlow Lite Micro no ESP-IDF](#-7-instalando-o-tensorflow-lite-micro-no-esp-idf)
8. [Processo completo: Keras ‚Üí TFLite ‚Üí TFLite Micro ‚Üí C/C++](#-8-pipeline-completo-keras--tflite--c-para-esp32-s3)

   * [Treinamento do modelo](#81-treinamento-do-modelo-keras)
   * [Fine-tuning](#82-compara√ß√£o-das-arquiteturas-resumo)
   * [MobileNetV2 vs MobileNetV3 vs modelo customizado](#82-compara√ß√£o-das-arquiteturas-resumo)
   * [Convers√£o para TFLite](#83-convers√£o-para-tflite)
   * [Quantiza√ß√£o (INT8)](#84-quantiza√ß√£o-int8-fundamental-para-microcontroladores)
   * [Gera√ß√£o do modelo est√°tico para C](#86-converter-para-c-array-usado-no-esp-idf)
9. [Compilar, fazer flash e monitorar no ESP32-S3](#-9-build-flash-e-monitor)
10. [Uso da mem√≥ria, arena e otimiza√ß√µes](#-10-mem√≥ria-arena-e-otimiza√ß√µes)
11. [Limita√ß√µes importantes](#-11-limita√ß√µes-importantes)
12. [Boas pr√°ticas](#-12-boas-pr√°ticas)
13. [Links √∫teis](#-13-recursos-e-links-√∫teis)
14. [Licen√ßa](#-14-licen√ßa)

---

# ‚ú® **1. Introdu√ß√£o**

Este projeto demonstra, de forma completa e did√°tica, como levar um modelo de **Deep Learning** ‚Äî treinado com **TensorFlow/Keras** ‚Äî para execu√ß√£o totalmente embarcada no **ESP32-S3**, sem internet e sem depender de servidores ou acelera√ß√£o externa.

Utiliza-se o **TensorFlow Lite Micro**, adaptado pela Espressif via o componente:

> **esp-tflite-micro** (vers√£o recomendada: **v1.3.5**)

Com isso, √© poss√≠vel realizar infer√™ncias de modelos CNN diretamente no microcontrolador, mesmo com recursos extremamente limitados.

Este reposit√≥rio apresenta:

‚úì C√≥digo-fonte completo em C/C++ para ESP-IDF<br>
‚úì Modelos treinados (MobileNetV2, MobileNetV3 e modelo customizado)<br>
‚úì Arquivos `.tflite` (normal, quantizado, din√¢mico*)<br>
‚úì Convers√£o para C array (`model_data.cc`)<br>
‚úì Notebooks de treinamento<br>
‚úì An√°lises de desempenho e mem√≥rias<br>

---

# üéØ **2. Objetivo do projeto**

O objetivo √© fornecer **um pipeline completo**, replic√°vel e totalmente funcional, para:

* Treinar um modelo CNN (do zero ou fine-tuning)
* Comparar arquiteturas adequadas para microcontroladores
* Converter para TFLite e otimizar via quantiza√ß√£o
* Gerar modelos compat√≠veis com TFLite Micro
* Executar infer√™ncia no ESP32-S3 com baixo consumo de RAM
* Fazer toda a integra√ß√£o em C/C++ com ESP-IDF

√â um guia completo de TinyML aplicado **na pr√°tica**.

---

# **3. Arquitetura geral**

```mermaid
graph LR
A[Treinamento Keras] --> B[Convers√£o .tflite]
B --> C[Quantiza√ß√£o INT8]
C --> D[Convers√£o Hex xxd]
D --> E[Firmware C++ ESP-IDF]
E --> F[Infer√™ncia no ESP32-S3]
```

---

# üìÇ **4. Estrutura do reposit√≥rio**

```
ESP32_TinyML
‚îú‚îÄ‚îÄ Esp32S3                  # Firmware principal (ESP-IDF Project)
‚îÇ   ‚îú‚îÄ‚îÄ CMakeLists.txt
‚îÇ   ‚îî‚îÄ‚îÄ main
‚îÇ       ‚îú‚îÄ‚îÄ CMakeLists.txt
‚îÇ       ‚îú‚îÄ‚îÄ idf_component.yml # Gerenciador de depend√™ncias (TFLM)
‚îÇ       ‚îú‚îÄ‚îÄ main.cpp          # Entry point (app_main)
‚îÇ       ‚îú‚îÄ‚îÄ main_functions.cc # Setup do TFLite e Loop de infer√™ncia
‚îÇ       ‚îú‚îÄ‚îÄ model.h           # Cabe√ßalho do modelo
‚îÇ       ‚îî‚îÄ‚îÄ model_data.cc     # Modelo treinado convertido em byte array
‚îú‚îÄ‚îÄ Modelos                  # Arquivos .keras e .tflite gerados
‚îÇ   ‚îú‚îÄ‚îÄ Customizado
‚îÇ   ‚îú‚îÄ‚îÄ V2 (MobileNetV2)
‚îÇ   ‚îî‚îÄ‚îÄ V3 (MobileNetV3)
‚îú‚îÄ‚îÄ Treinamento              # Jupyter Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ CNN_Lite.ipynb       # Notebook completo
‚îÇ   ‚îî‚îÄ‚îÄ CNN_Lite_limpo.ipynb # Vers√£o otimizada para visualiza√ß√£o
‚îî‚îÄ‚îÄ LICENSE
```

---

# **5. Requisitos**

## üîå **Hardware**

* ESP32-S3 DevKitC-1 (recomendado)
* Cabo USB
* Opcional: c√¢mera, sensores etc.

---

## üñ•Ô∏è **Software**

* **VS Code**
* **Extens√£o ESP-IDF**
* ESP-IDF (vers√£o 4.x ou 5.x compat√≠vel com esp-tflite-micro)
* Python 3.8+
* TensorFlow ‚â• 2.6 (recomendado 2.6 para compatibilidade total)
* Ferramenta `xxd` (Linux/macOS) para gerar arquivos C
* Git

---

# ‚öôÔ∏è **6. Prepara√ß√£o do ambiente (VS Code + ESP-IDF)**

1. Instale o VS Code
2. Instale a extens√£o **Espressif IDF**
3. Configure o ESP-IDF pelo assistente da pr√≥pria extens√£o
4. Abra a pasta `ESP32_TinyML/Esp32S3`
5. Caso esteja no terminal, ative manualmente:

```bash
source $IDF_PATH/export.sh
```

---

# üì¶ **7. Instalando o esp-tflite-micro**

O componente oficial utilizado:

üîó [https://github.com/espressif/esp-tflite-micro/tree/v1.3.5](https://github.com/espressif/esp-tflite-micro/tree/v1.3.5)

Instala√ß√£o autom√°tica no projeto:

```bash
idf.py add-dependency "esp-tflite-micro"
```

O pr√≥prio ESP-IDF baixa e instala o componente.

---

# üß† **8. Pipeline completo: Keras ‚Üí TFLite ‚Üí C para ESP32-S3**

## 8.1 Treinamento do modelo (Keras)

Pode ser feito:

* **Do zero** (modelo customizado, leve e muito eficiente)
* **Fine-tuning** usando:

  * MobileNetV2
  * MobileNetV3
  * Outras arquiteturas suportadas

Os notebooks deste projeto mostram:

* Prepara√ß√£o dos Dados
* Treinamento
* Fine Tuning
* Coners√£o
* Comparativo entre modelos

---

## 8.2 Compara√ß√£o das arquiteturas (resumo)

### **MobileNetV2**

* Excelente equil√≠brio entre tamanho e acur√°cia
* Funciona muito bem ap√≥s quantiza√ß√£o

### **MobileNetV3**

* Excelente para dispositivos m√≥veis
* No TinyML, a convers√£o + quantiza√ß√£o pode causar **queda de desempenho**, dependendo das opera√ß√µes utilizadas
* N√£o √© um problema da arquitetura, mas sim da compatibilidade e forma como algumas camadas s√£o quantizadas

### **Modelo Customizado**

* O melhor para ESP32-S3
* Controle total sobre profundidade, filtros, entrada
* Geralmente exige muito menos arena TFLM

---

## 8.3 Convers√£o para TFLite

Convers√£o simples:

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite = converter.convert()
open("modelo_normal.tflite", "wb").write(tflite)
```

---

## 8.4 Quantiza√ß√£o INT8 (fundamental para microcontroladores)

A quantiza√ß√£o reduz:

* Tamanho do arquivo
* Consumo de RAM
* Tamanho da arena TFLM

Exemplo:

```python
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
```

---

## 8.5 Sobre modelos din√¢micos

Modelos "din√¢micos" (com tensores alocados em tamanho vari√°vel ou operadores que exigem realoca√ß√£o) **n√£o s√£o suportados pelo TFLite Micro**.

Mesmo que suas m√©tricas sejam calculadas, **n√£o podem ser usados no ESP32-S3**.

No reposit√≥rio, eles foram mantidos apenas para fins de compara√ß√£o.

---

Abaixo est√° uma **vers√£o organizada, limpa e padronizada** da sua se√ß√£o **8.6 Converter para C Array**, pronta para colocar no README.
Fiz de forma clara, profissional e sem repeti√ß√£o ‚Äî seguindo o estilo de documenta√ß√£o usado nos reposit√≥rios oficiais do ESP-IDF e Espressif.

---

# ‚úÖ **8.6 Convers√£o do modelo TFLite para C Array (para uso no ESP-IDF)**

Para utilizar um modelo `.tflite` dentro do ESP32-S3, ele precisa ser convertido para um **array C**.
Isso permite incluir o modelo diretamente no firmware, sem depender de arquivos externos.

---

## üîß **1. Converter o arquivo `.tflite` em c√≥digo C**

Use o comando:

```bash
xxd -i modelo_inteiro.tflite > model_data.cc
```

Esse comando cria um arquivo `model_data.cc` contendo o modelo em formato de array.

---

## ‚úèÔ∏è **2. Ajustar o arquivo gerado**

Edite o in√≠cio e o fim do arquivo **model_data.cc** para ficar assim:

```c
#include "model.h"

alignas(16) const unsigned char modelo_tflite[] = {
    // Conte√∫do gerado automaticamente pelo xxd
};

const unsigned int modelo_tflite_len = /* tamanho gerado pelo xxd */;
```

O `alignas(16)` √© recomendado para evitar erros de alinhamento no TFLite Micro.

---

## üß© **3. Criar o arquivo de cabe√ßalho `model.h`**

Crie o arquivo **model.h** na mesma pasta:

```c
#ifndef MODEL_H_
#define MODEL_H_

#include <cstdint>

extern const unsigned char modelo_tflite[];
extern const unsigned int modelo_tflite_len;

#endif
```

Esse arquivo permite que o modelo seja usado em qualquer parte do seu c√≥digo C/C++.

---

## üîó **4. Incluir no seu programa**

No `main.cpp` ou `main_functions.cc`:

```c
#include "model.h"
```

Agora o modelo pode ser carregado pelo TFLite Micro normalmente:

```c
const tflite::Model* model = tflite::GetModel(modelo_tflite);
```

---

# üõ†Ô∏è **9. Build, Flash e Monitor**

Na pasta `Esp32S3`:

```bash
idf.py menuconfig
idf.py build
idf.py -p /dev/ttyUSB0 flash
idf.py -p /dev/ttyUSB0 monitor
```

Sair do monitor:
`CTRL + ]`

Tamb√©m √© poss√≠vel usar os bot√µes do ESP-IDF dentro do VS Code.

---

# üíæ **10. Mem√≥ria, arena e otimiza√ß√µes**

Com base em medi√ß√µes reais feitas no ESP32-S3:

### **SRAM interna livre (~361 KB)**

* Maior bloco cont√≠guo (~303 KB)

### **Arena ideal estimada: 280‚Äì290 KB**

A arena precisa ser cont√≠gua.
Modelos maiores falham mesmo se houver RAM livre.

### **Dicas de otimiza√ß√£o**

* Use **quantiza√ß√£o INT8**
* Reduza o tamanho de entrada do modelo
* Diminua n√∫mero de filtros
* Evite camadas complexas
* Pruning e distillation podem ser √∫teis

---

# ‚ö†Ô∏è **11. Limita√ß√µes importantes**

* **Modelos Din√¢micos** ‚Üí n√£o funcionam no TFLM
* MobileNetV3 pode apresentar **queda de desempenho ap√≥s convers√£o**
* O ESP32-S3 n√£o suporta operadores avan√ßados do TensorFlow
* A arena deve estar **inteira na SRAM interna**

---

# üìò **12. Boas pr√°ticas**

* Sempre teste a acur√°cia **ap√≥s** a convers√£o para TFLite
* Gere um representative dataset variado
* Monitore o uso de heap no log do ESP-IDF
* Use PSRAM apenas para buffers auxiliares, n√£o para arena
* Evite modelos acima de ~350 KB (tflite) se n√£o forem quantizados

---

# üîó **13. Recursos e links √∫teis**

* **esp-tflite-micro (1.3.5):**
  [https://github.com/espressif/esp-tflite-micro/tree/v1.3.5](https://github.com/espressif/esp-tflite-micro/tree/v1.3.5)

* **Documenta√ß√£o ESP-IDF:**
  [https://docs.espressif.com](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html)

* **Convers√£o TFLite:**
  [https://www.tensorflow.org/lite/convert](https://www.tensorflow.org/lite/convert)

* **Link de Compra**
   [https://www.makerhero.com/produto/placa-esp32-s3-devkitc/:](https://www.makerhero.com/produto/placa-esp32-s3-devkitc/)

---

# üìÑ **14. Licen√ßa**

Veja o arquivo `LICENSE` na raiz do projeto.

---
# ğŸŒŸ **ESP32_TinyML â€“ InferÃªncia de Redes Neurais no ESP32-S3**

<p align="left">
  <img src="https://img.shields.io/badge/ESP32_S3-Espressif-E7352C?style=for-the-badge&logo=espressif&logoColor=white" />
  <img src="https://img.shields.io/badge/C-00599C?style=for-the-badge&logo=c&logoColor=white" />
  <img src="https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=cplusplus&logoColor=white" />
  <img src="https://img.shields.io/badge/TFLite_Micro-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" />
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" />
  <img src="https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/ESP--IDF-000000?style=for-the-badge&logo=espressif&logoColor=white" />
 
</p>

**Uma soluÃ§Ã£o completa de Edge AI (TinyML) com TensorFlow Lite Micro**

**Autor:** *Kelton Martins Dias*<br>
**Orientador:** *Prof. Felipe Mota*

---

## ğŸ“Œ **SumÃ¡rio**

1. [IntroduÃ§Ã£o](#-1-introduÃ§Ã£o)
2. [Objetivo do projeto](#-2-objetivo-do-projeto)
3. [Arquitetura geral](#-3-arquitetura-geral)
4. [Estrutura do repositÃ³rio](#-4-estrutura-do-repositÃ³rio)
5. [Requisitos](#-5-requisitos)

   * [Hardware](#-hardware)
   * [Software](#-software)
6. [PreparaÃ§Ã£o do ambiente (VS Code + ESP-IDF)](#-6-preparaÃ§Ã£o-do-ambiente-vs-code--esp-idf)
7. [Instalando o TensorFlow Lite Micro no ESP-IDF](#-7-instalando-o-tensorflow-lite-micro-no-esp-idf)
8. [Processo completo: Keras â†’ TFLite â†’ TFLite Micro â†’ C/C++](#-8-pipeline-completo-keras--tflite--c-para-esp32-s3)

   * [Treinamento do modelo](#81-treinamento-do-modelo-keras)
   * [Fine-tuning](#82-comparaÃ§Ã£o-das-arquiteturas-resumo)
   * [MobileNetV2 vs MobileNetV3 vs modelo customizado](#82-comparaÃ§Ã£o-das-arquiteturas-resumo)
   * [ConversÃ£o para TFLite](#83-conversÃ£o-para-tflite)
   * [QuantizaÃ§Ã£o (INT8)](#84-quantizaÃ§Ã£o-int8-fundamental-para-microcontroladores)
   * [GeraÃ§Ã£o do modelo estÃ¡tico para C](#86-converter-para-c-array-usado-no-esp-idf)
9. [Compilar, fazer flash e monitorar no ESP32-S3](#-9-build-flash-e-monitor)
10. [Uso da memÃ³ria, arena e otimizaÃ§Ãµes](#-10-memÃ³ria-arena-e-otimizaÃ§Ãµes)
11. [LimitaÃ§Ãµes importantes](#-11-limitaÃ§Ãµes-importantes)
12. [Boas prÃ¡ticas](#-12-boas-prÃ¡ticas)
13. [Links Ãºteis](#-13-recursos-e-links-Ãºteis)
14. [LicenÃ§a](#-14-licenÃ§a)

---

# âœ¨ **1. IntroduÃ§Ã£o**

Este projeto demonstra, de forma completa e didÃ¡tica, como levar um modelo de **Deep Learning** â€” treinado com **TensorFlow/Keras** â€” para execuÃ§Ã£o totalmente embarcada no **ESP32-S3**, sem internet e sem depender de servidores ou aceleraÃ§Ã£o externa.

Utiliza-se o **TensorFlow Lite Micro**, adaptado pela Espressif via o componente:

> **esp-tflite-micro** (versÃ£o recomendada: **v1.3.5**)

Com isso, Ã© possÃ­vel realizar inferÃªncias de modelos CNN diretamente no microcontrolador, mesmo com recursos extremamente limitados.

Este repositÃ³rio apresenta:

âœ“ CÃ³digo-fonte completo em C/C++ para ESP-IDF<br>
âœ“ Modelos treinados (MobileNetV2, MobileNetV3 e modelo customizado)<br>
âœ“ Arquivos `.tflite` (normal, quantizado, dinÃ¢mico*)<br>
âœ“ ConversÃ£o para C array (`model_data.cc`)<br>
âœ“ Notebooks de treinamento<br>
âœ“ AnÃ¡lises de desempenho e memÃ³rias<br>

---

# ğŸ¯ **2. Objetivo do projeto**

O objetivo Ã© fornecer **um pipeline completo**, replicÃ¡vel e totalmente funcional, para:

* Treinar um modelo CNN (do zero ou fine-tuning)
* Comparar arquiteturas adequadas para microcontroladores
* Converter para TFLite e otimizar via quantizaÃ§Ã£o
* Gerar modelos compatÃ­veis com TFLite Micro
* Executar inferÃªncia no ESP32-S3 com baixo consumo de RAM
* Fazer toda a integraÃ§Ã£o em C/C++ com ESP-IDF

Ã‰ um guia completo de TinyML aplicado **na prÃ¡tica**.

---

# **3. Arquitetura geral**

```mermaid
graph LR
A[Treinamento Keras] --> B[ConversÃ£o .tflite]
B --> C[QuantizaÃ§Ã£o INT8]
C --> D[ConversÃ£o Hex xxd]
D --> E[Firmware C++ ESP-IDF]
E --> F[InferÃªncia no ESP32-S3]
```

---

# ğŸ“‚ **4. Estrutura do repositÃ³rio**

```
ESP32_TinyML
â”œâ”€â”€ Esp32S3                  # Firmware principal (ESP-IDF Project)
â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â””â”€â”€ main
â”‚       â”œâ”€â”€ CMakeLists.txt
â”‚       â”œâ”€â”€ idf_component.yml # Gerenciador de dependÃªncias (TFLM)
â”‚       â”œâ”€â”€ main.cpp          # Entry point (app_main)
â”‚       â”œâ”€â”€ main_functions.cc # Setup do TFLite e Loop de inferÃªncia
â”‚       â”œâ”€â”€ model.h           # CabeÃ§alho do modelo
â”‚       â””â”€â”€ model_data.cc     # Modelo treinado convertido em byte array
â”œâ”€â”€ Modelos                  # Arquivos .keras e .tflite gerados
â”‚   â”œâ”€â”€ Customizado
â”‚   â”œâ”€â”€ V2 (MobileNetV2)
â”‚   â””â”€â”€ V3 (MobileNetV3)
â”œâ”€â”€ Treinamento              # Jupyter Notebooks
â”‚   â”œâ”€â”€ CNN_Lite.ipynb       # Notebook completo
â”‚   â””â”€â”€ CNN_Lite_limpo.ipynb # VersÃ£o otimizada para visualizaÃ§Ã£o
â””â”€â”€ LICENSE
```

---

# **5. Requisitos**

## ğŸ”Œ **Hardware**

* ESP32-S3 DevKitC-1 (recomendado)
* Cabo USB
* Opcional: cÃ¢mera, sensores etc.

---

## ğŸ–¥ï¸ **Software**

* **VS Code**
* **ExtensÃ£o ESP-IDF**
* ESP-IDF (versÃ£o 4.x ou 5.x compatÃ­vel com esp-tflite-micro)
* Python 3.8+
* TensorFlow â‰¥ 2.6 (recomendado 2.6 para compatibilidade total)
* Ferramenta `xxd` (Linux/macOS) para gerar arquivos C
* Git

---

# âš™ï¸ **6. PreparaÃ§Ã£o do ambiente (VS Code + ESP-IDF)**

1. Instale o VS Code
2. Instale a extensÃ£o **Espressif IDF**
3. Configure o ESP-IDF pelo assistente da prÃ³pria extensÃ£o
4. Abra a pasta `ESP32_TinyML/Esp32S3`
5. Caso esteja no terminal, ative manualmente:

```bash
source $IDF_PATH/export.sh
```

---

# ğŸ“¦ **7. Instalando o esp-tflite-micro**

O componente oficial utilizado:

ğŸ”— [https://github.com/espressif/esp-tflite-micro/tree/v1.3.5](https://github.com/espressif/esp-tflite-micro/tree/v1.3.5)

InstalaÃ§Ã£o automÃ¡tica no projeto:

```bash
idf.py add-dependency "esp-tflite-micro"
```

O prÃ³prio ESP-IDF baixa e instala o componente.

---

# ğŸ§  **8. Pipeline completo: Keras â†’ TFLite â†’ C para ESP32-S3**

## 8.1 Treinamento do modelo (Keras)

Pode ser feito:

* **Do zero** (modelo customizado, leve e muito eficiente)
* **Fine-tuning** usando:

  * MobileNetV2
  * MobileNetV3
  * Outras arquiteturas suportadas

Os notebooks deste projeto mostram:

* Aumento de dados
* Mixed precision
* EstratÃ©gias de regularizaÃ§Ã£o
* Comparativo entre modelos

---

## 8.2 ComparaÃ§Ã£o das arquiteturas (resumo)

### **MobileNetV2**

* Excelente equilÃ­brio entre tamanho e acurÃ¡cia
* Funciona muito bem apÃ³s quantizaÃ§Ã£o

### **MobileNetV3**

* Excelente para dispositivos mÃ³veis
* No TinyML, a conversÃ£o + quantizaÃ§Ã£o pode causar **queda de desempenho**, dependendo das operaÃ§Ãµes utilizadas
* NÃ£o Ã© um problema da arquitetura, mas sim da compatibilidade e forma como algumas camadas sÃ£o quantizadas

### **Modelo Customizado**

* O melhor para ESP32-S3
* Controle total sobre profundidade, filtros, entrada
* Geralmente exige muito menos arena TFLM

---

## 8.3 ConversÃ£o para TFLite

ConversÃ£o simples:

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite = converter.convert()
open("modelo_normal.tflite", "wb").write(tflite)
```

---

## 8.4 QuantizaÃ§Ã£o INT8 (fundamental para microcontroladores)

A quantizaÃ§Ã£o reduz:

* Tamanho do arquivo
* Consumo de RAM
* Tamanho da arena TFLM

Exemplo:

```python
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
```

---

## 8.5 Sobre modelos dinÃ¢micos

Modelos "dinÃ¢micos" (com tensores alocados em tamanho variÃ¡vel ou operadores que exigem realocaÃ§Ã£o) **nÃ£o sÃ£o suportados pelo TFLite Micro**.

Mesmo que suas mÃ©tricas sejam calculadas, **nÃ£o podem ser usados no ESP32-S3**.

No repositÃ³rio, eles foram mantidos apenas para fins de comparaÃ§Ã£o.

---

## 8.6 Converter para C Array (usado no ESP-IDF)

```bash
xxd -i modelo_inteiro.tflite > model_data.cc
```

Depois, basta adicionar no cÃ³digo:

```c
#include "model_data.cc"
```

E referenciar no `model.h`.

---

# ğŸ› ï¸ **9. Build, Flash e Monitor**

Na pasta `Esp32S3`:

```bash
idf.py menuconfig
idf.py build
idf.py -p /dev/ttyUSB0 flash
idf.py -p /dev/ttyUSB0 monitor
```

Sair do monitor:
`CTRL + ]`

TambÃ©m Ã© possÃ­vel usar os botÃµes do ESP-IDF dentro do VS Code.

---

# ğŸ’¾ **10. MemÃ³ria, arena e otimizaÃ§Ãµes**

Com base em mediÃ§Ãµes reais feitas no ESP32-S3:

### **SRAM interna livre (~361 KB)**

* Maior bloco contÃ­guo (~303 KB)

### **Arena ideal estimada: 280â€“290 KB**

A arena precisa ser contÃ­gua.
Modelos maiores falham mesmo se houver RAM livre.

### **Dicas de otimizaÃ§Ã£o**

* Use **quantizaÃ§Ã£o INT8**
* Reduza o tamanho de entrada do modelo
* Diminua nÃºmero de filtros
* Evite camadas complexas
* Pruning e distillation podem ser Ãºteis

---

# âš ï¸ **11. LimitaÃ§Ãµes importantes**

* **Modelos DinÃ¢micos** â†’ nÃ£o funcionam no TFLM
* MobileNetV3 pode apresentar **queda de desempenho apÃ³s conversÃ£o**
* O ESP32-S3 nÃ£o suporta operadores avanÃ§ados do TensorFlow
* A arena deve estar **inteira na SRAM interna**

---

# ğŸ“˜ **12. Boas prÃ¡ticas**

* Sempre teste a acurÃ¡cia **apÃ³s** a conversÃ£o para TFLite
* Gere um representative dataset variado
* Monitore o uso de heap no log do ESP-IDF
* Use PSRAM apenas para buffers auxiliares, nÃ£o para arena
* Evite modelos acima de ~350 KB (tflite) se nÃ£o forem quantizados

---

# ğŸ”— **13. Recursos e links Ãºteis**

* **esp-tflite-micro (1.3.5):**
  [https://github.com/espressif/esp-tflite-micro/tree/v1.3.5](https://github.com/espressif/esp-tflite-micro/tree/v1.3.5)

* **DocumentaÃ§Ã£o ESP-IDF:**
  [https://docs.espressif.com](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html)

* **ConversÃ£o TFLite:**
  [https://www.tensorflow.org/lite/convert](https://www.tensorflow.org/lite/convert)

* **Link de Compra**
   [https://www.makerhero.com/produto/placa-esp32-s3-devkitc/:](https://www.makerhero.com/produto/placa-esp32-s3-devkitc/)

---

# ğŸ“„ **14. LicenÃ§a**

Veja o arquivo `LICENSE` na raiz do projeto.

---